# -*- coding: utf-8 -*-
"""LogsData.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12ptqsiyvrgCmeNpgwKIzKBXnt-Jh5iAx
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import re
import string
import csv
import json
import nltk
import math
from wordcloud import WordCloud, STOPWORDS
import matplotlib.pyplot as plt

from nltk.tokenize import sent_tokenize
from nltk.corpus import words
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from nltk.stem import PorterStemmer
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from nltk.sentiment.util import *
nltk.download('stopwords')
nltk.download('vader_lexicon')

from collections import Counter, defaultdict

from matplotlib import pyplot as plt
from matplotlib import ticker
import plotly.express as px

# sns.set(style="darkgrid")

"""# Importing the dataset from Google Drive"""

from google.colab import drive
drive.mount('/content/drive')

datasetDocument = pd.read_json('/content/drive/My Drive/Colab Notebooks/Proj/Dataset_1/Documents/Documents_Dataset_1.json')
datasetSegmentation = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Proj/Dataset_1/Segmentation/Arms_P1_20_4_6_Prov_Segments.csv')
datasetUserInteractions = pd.read_json('/content/drive/My Drive/Colab Notebooks/Proj/Dataset_1/User Interactions/Arms_P1_InteractionsLogs.json')

datasetSegmentation.info()

segmentID = datasetSegmentation['ID']
segmentStart = datasetSegmentation['start'] * 10
segmentEnd = datasetSegmentation['end'] * 10
segmentDuration = datasetSegmentation['length (sec)'] * 10

datasetUserInteractions.info()

interactionType = datasetUserInteractions['InteractionType']
interactionText = datasetUserInteractions['Text']
interactionTime = datasetUserInteractions['time']
interactionDuration = datasetUserInteractions['duration']

"""# Creation of the Dataframe for Interaction Summary"""

userSummaryDF = pd.DataFrame(columns=['UserID', 'SegmentID', 'Start', 'End', '# Interactions', '# Documents Opened', 'Opened Documents', 'OpenDuration',
                                      '# Documents Read', 'Read Documents', 'ReadDuration', '# Documents Dragged', 'Dragged Documents', 'DraggingDuration',
                                      'Most Read Document', '# Highlighted', 'Highlighted Words', 'HighlightingDuration', '# Searched', 'Searched Words',
                                      'SearchDuration'])

totalSegments = len(segmentID)
numOfInteractions = len(interactionTime)
segmentIndex = 0
figureCount = math.ceil(np.sqrt(totalSegments))
uIndex = 0

allSearchedWords = []
allHighlightedWords = []
allReadDocuments = []
allDraggedDocuments = []
allOpenedDocuments = []

while segmentIndex < totalSegments:
  interactionCount = 0
  searchedWords = []
  highlightedWords = []

  draggedDocuments = []
  openedDocuments = []
  readDocuments = []

  openDuration = 0
  readDuration = 0
  draggingDuration = 0
  highlightDuration = 0
  searchDuration = 0

  currTime = int(interactionTime[uIndex])
  end = int(segmentEnd[segmentIndex])

  while currTime <= end:
    if(interactionType[uIndex].lower() == 'search'):
      searchedWords.append(interactionText[uIndex])
      searchDuration += interactionDuration[uIndex]
      interactionCount += 1
    elif(interactionType[uIndex].lower() == 'highlight'):
      highlightedWords.append(interactionText[uIndex])
      highlightDuration += interactionDuration[uIndex]
      interactionCount += 1
    elif(interactionType[uIndex].lower() == 'reading'):
      readDocuments.append(interactionText[uIndex])
      readDuration += interactionDuration[uIndex]
      interactionCount += 1
    elif(interactionType[uIndex].lower() == 'doc_open'):
      openedDocuments.append(interactionText[uIndex])
      openDuration += interactionDuration[uIndex]
      interactionCount += 1
    elif(interactionType[uIndex].lower() == 'draging'):
      draggedDocuments.append(interactionText[uIndex])
      draggingDuration += interactionDuration[uIndex]
      interactionCount += 1
    uIndex += 1

    if(uIndex < numOfInteractions):
      currTime = interactionTime[uIndex]

  swf = dict(Counter(searchedWords))

  searchedWordsFreq = [k for k, v in sorted(swf.items(), key=lambda item: item[1], reverse=True)]

  readDocsFreq = dict(Counter(readDocuments))
  mostReadDocument = str(max(readDocsFreq, key=readDocsFreq.get)) if len(readDocsFreq) != 0 else "NA"

  # All values
  allSearchedWords.extend(searchedWords)
  allHighlightedWords.extend(highlightedWords)
  allReadDocuments.extend(readDocuments)
  allOpenedDocuments.extend(openedDocuments)
  allDraggedDocuments.extend(draggedDocuments)

  startTime = int(segmentStart[segmentIndex])/10
  endTime = int(segmentEnd[segmentIndex])/10

  cntDocumentsOpened = len(openedDocuments)
  uniqueDocumentsOpened = np.unique(openedDocuments)

  cntDocumentsRead = len(readDocuments)
  uniqueDocumentsRead = np.unique(readDocuments)

  cntDocumentsDragged = len(draggedDocuments)
  uniqueDocumentsDragged = np.unique(draggedDocuments)

  cntHighlights = len(highlightedWords)
  cntSearches = len(searchedWords)

  userSummaryDF.loc[len(userSummaryDF.index)] = [1, segmentIndex+1, startTime, endTime, interactionCount, cntDocumentsOpened,
                                                 uniqueDocumentsOpened, openDuration/10, cntDocumentsRead, uniqueDocumentsRead, readDuration/10, cntDocumentsDragged,
                                                 uniqueDocumentsDragged, draggingDuration/10, mostReadDocument, cntHighlights, highlightedWords,
                                                 highlightDuration/10, cntSearches, searchedWordsFreq, searchDuration/10]
  segmentIndex += 1

"""# Viewing the Dataset"""

userSummaryDF

"""# Exporting the Dataset"""

userSummaryDF.to_csv(r'/content/drive/My Drive/Colab Notebooks/Proj/Dataset_3/Summaries/Dataset3_4.csv')

"""# Dividing the dataset into multiple Segments & average value calculation for each interaction"""

userSummaryDF.head()

df_RangeAverage = pd.DataFrame(columns=['SegmentRangeID', 'SegmentSize', 'Open_Count', 'AverageOpens', 'ReadDocument_Count', 'AverageReads',
                                        'DraggedDocument_Count', 'AverageDrags', 'HighlightCount', 'AverageHighlights', 'SearchCount', 'AverageSearches'])

figureCount = math.ceil(np.sqrt(totalSegments))
segmentRangeID = 0
count = 0

while(count < totalSegments):
  currFigureCount = 0

  openCount = 0
  readCount = 0
  dragCount = 0
  highlightCount = 0
  searchCount = 0

  while(count < totalSegments and currFigureCount < figureCount):
    openCount += userSummaryDF.iloc[count]["# Documents Opened"]
    readCount += userSummaryDF.iloc[count]["# Documents Read"]
    dragCount += userSummaryDF.iloc[count]["# Documents Dragged"]
    highlightCount += userSummaryDF.iloc[count]["# Highlighted"]
    searchCount += userSummaryDF.iloc[count]["# Searched"]

    currFigureCount += 1
    count += 1
  segmentRangeID += 1
  df_RangeAverage.loc[len(df_RangeAverage.index)] = [segmentRangeID, currFigureCount, openCount, str(round(openCount/currFigureCount, 1)), readCount, str(round(readCount/currFigureCount, 2)),
                                                     dragCount, str(round(dragCount/currFigureCount, 2)), highlightCount, str(round(highlightCount/currFigureCount, 2)),
                                                     searchCount, str(round(searchCount/currFigureCount, 2))]

df_RangeAverage

"""# Exporting Segment Range"""

df_RangeAverage.to_csv(r'/content/drive/My Drive/Colab Notebooks/Proj/segmentRangeDataset.csv')

# Cleaning the dataset
def createWordCloud(cList, title, isDoc = False):
  temp = []
  for word in cList:
    words = word.strip().strip("\\").split(" ") if not isDoc else word.replace(" ", "")
    if not isDoc:
      for item in words:
        if item.isalnum():
          temp.append(item.lower())
    else:
      temp.append(words.lower())


  # Making a word cloud for 20 words
  wCloud = " ".join(sorted(Counter(temp)))
  wordcloud = WordCloud(width = 800, height = 800,
                  background_color ='white',
                  min_font_size = 10, include_numbers=True).generate(wCloud)
  plt.figure(figsize = (8, 8), facecolor = None)
  plt.imshow(wordcloud)
  plt.axis("off")
  plt.tight_layout(pad = 0)
  plt.title(title)
  plt.show()

createWordCloud(allSearchedWords, "Searched Words")

createWordCloud(allHighlightedWords, "Highlighted Words")

createWordCloud(allOpenedDocuments, "Opened Documents", True)

datasetDocument = pd.read_json('/content/drive/My Drive/Colab Notebooks/Proj/Dataset_1/Documents/Documents_Dataset_1.json')
datasetSegmentation = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Proj/Dataset_1/Segmentation/Arms_P1_20_4_6_Prov_Segments.csv')
datasetUserInteractions = pd.read_json('/content/drive/My Drive/Colab Notebooks/Proj/Dataset_1/User Interactions/Arms_P1_InteractionsLogs.json')

segmentID = datasetSegmentation['ID']
segmentStart = datasetSegmentation['start'] * 10
segmentEnd = datasetSegmentation['end'] * 10
segmentDuration = datasetSegmentation['length (sec)'] * 10

interactionType = datasetUserInteractions['InteractionType']
interactionText = datasetUserInteractions['Text']
interactionTime = datasetUserInteractions['time']
interactionDuration = datasetUserInteractions['duration']

userSummaryDF = pd.DataFrame(columns=['UserID', 'SegmentID', 'Start', 'End', '# Interactions', '# Documents Opened', 'Opened Documents', 'OpenDuration',
                                      '# Documents Read', 'Read Documents', 'ReadDuration', '# Documents Dragged', 'Dragged Documents', 'DraggingDuration',
                                      'Most Read Document', '# Highlighted', 'Highlighted Words', 'HighlightingDuration', '# Searched', 'Searched Words',
                                      'SearchDuration'])

totalSegments = len(segmentID)
numOfInteractions = len(interactionTime)
segmentIndex = 0
figureCount = math.ceil(np.sqrt(totalSegments))
uIndex = 0

allSearchedWords = []
allHighlightedWords = []
allReadDocuments = []
allDraggedDocuments = []
allOpenedDocuments = []

while segmentIndex < totalSegments:
  interactionCount = 0
  searchedWords = []
  highlightedWords = []

  draggedDocuments = []
  openedDocuments = []
  readDocuments = []

  openDuration = 0
  readDuration = 0
  draggingDuration = 0
  highlightDuration = 0
  searchDuration = 0

  currTime = int(interactionTime[uIndex])
  end = int(segmentEnd[segmentIndex])

  while currTime <= end:
    if(interactionType[uIndex].lower() == 'search'):
      searchedWords.append(interactionText[uIndex])
      searchDuration += interactionDuration[uIndex]
      interactionCount += 1
    elif(interactionType[uIndex].lower() == 'highlight'):
      highlightedWords.append(interactionText[uIndex])
      highlightDuration += interactionDuration[uIndex]
      interactionCount += 1
    elif(interactionType[uIndex].lower() == 'reading'):
      readDocuments.append(interactionText[uIndex])
      readDuration += interactionDuration[uIndex]
      interactionCount += 1
    elif(interactionType[uIndex].lower() == 'doc_open'):
      openedDocuments.append(interactionText[uIndex])
      openDuration += interactionDuration[uIndex]
      interactionCount += 1
    elif(interactionType[uIndex].lower() == 'draging'):
      draggedDocuments.append(interactionText[uIndex])
      draggingDuration += interactionDuration[uIndex]
      interactionCount += 1
    uIndex += 1

    if(uIndex < numOfInteractions):
      currTime = interactionTime[uIndex]

  swf = dict(Counter(searchedWords))

  searchedWordsFreq = [k for k, v in sorted(swf.items(), key=lambda item: item[1], reverse=True)]

  readDocsFreq = dict(Counter(readDocuments))
  mostReadDocument = str(max(readDocsFreq, key=readDocsFreq.get)) if len(readDocsFreq) != 0 else "NA"

  # All values
  allSearchedWords.extend(searchedWords)
  allHighlightedWords.extend(highlightedWords)
  allReadDocuments.extend(readDocuments)
  allOpenedDocuments.extend(openedDocuments)
  allDraggedDocuments.extend(draggedDocuments)

  startTime = int(segmentStart[segmentIndex])/10
  endTime = int(segmentEnd[segmentIndex])/10

  cntDocumentsOpened = len(openedDocuments)
  uniqueDocumentsOpened = np.unique(openedDocuments)

  cntDocumentsRead = len(readDocuments)
  uniqueDocumentsRead = np.unique(readDocuments)

  cntDocumentsDragged = len(draggedDocuments)
  uniqueDocumentsDragged = np.unique(draggedDocuments)

  cntHighlights = len(highlightedWords)
  cntSearches = len(searchedWords)

  userSummaryDF.loc[len(userSummaryDF.index)] = [8, segmentIndex+1, startTime, endTime, interactionCount, cntDocumentsOpened,
                                                 uniqueDocumentsOpened, openDuration/10, cntDocumentsRead, uniqueDocumentsRead, readDuration/10, cntDocumentsDragged,
                                                 uniqueDocumentsDragged, draggingDuration/10, mostReadDocument, cntHighlights, highlightedWords,
                                                 highlightDuration/10, cntSearches, searchedWordsFreq, searchDuration/10]
  segmentIndex += 1
userSummaryDF = userSummaryDF.T
userSummaryDF.to_csv(r'/content/drive/My Drive/Colab Notebooks/Proj/transposedDataset.csv')

"""# Creation of User Interaction Summary Dataset"""

datasetDocument = pd.read_json('/content/drive/My Drive/Colab Notebooks/Proj/Dataset_3/Document/Documents_Dataset_3.json')
datasetSegmentation = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Proj/Dataset_3/Segmentation/Disappearance_P8_20_3_6_Prov_Segments.csv')
datasetUserInteractions = pd.read_json('/content/drive/My Drive/Colab Notebooks/Proj/Dataset_3/User Interactions/Disappearance_P8_InteractionsLogs.json')
userID = 8

segmentID = datasetSegmentation['ID']
segmentStart = datasetSegmentation['start'] * 10
segmentEnd = datasetSegmentation['end'] * 10
segmentDuration = datasetSegmentation['length (sec)'] * 10

interactionType = datasetUserInteractions['InteractionType']
interactionText = datasetUserInteractions['Text']
interactionTime = datasetUserInteractions['time']
interactionDuration = datasetUserInteractions['duration']

userInteractionSummaryDF = pd.DataFrame(columns=['UserID', 'InteractionType', 'Interaction Count', 'Interaction Duration'])

totalSegments = len(segmentID)
numOfInteractions = len(interactionTime)
segmentIndex = 0
uIndex = 0
l = []

openDuration, cntDocumentsOpened = 0, 0
readDuration, cntDocumentsRead = 0, 0
draggingDuration, cntDocumentsDragged = 0, 0
highlightDuration, cntHighlights = 0, 0
searchDuration, cntSearches = 0, 0

while segmentIndex < totalSegments:

  currTime = int(interactionTime[uIndex])
  end = int(segmentEnd[segmentIndex])

  while currTime <= end:
    if(uIndex == len(interactionType)):
      break
    if(interactionType[uIndex].lower() == 'search'):
      searchDuration += interactionDuration[uIndex]
      cntSearches += 1
    elif(interactionType[uIndex].lower() == 'highlight'):
      highlightDuration += interactionDuration[uIndex]
      cntHighlights += 1
    elif(interactionType[uIndex].lower() == 'reading'):
      readDuration += interactionDuration[uIndex]
      cntDocumentsRead += 1
    elif(interactionType[uIndex].lower() == 'doc_open'):
      openDuration += interactionDuration[uIndex]
      cntDocumentsOpened += 1
    elif(interactionType[uIndex].lower() == 'draging'):
      draggingDuration += interactionDuration[uIndex]
      cntDocumentsDragged += 1
    uIndex += 1

    if(uIndex < numOfInteractions):
      currTime = interactionTime[uIndex]
  l.append(cntDocumentsOpened)
  segmentIndex += 1
userInteractionSummaryDF.loc[len(userInteractionSummaryDF.index)] = [userID, 'Searches Performed', cntSearches, searchDuration//10]
userInteractionSummaryDF.loc[len(userInteractionSummaryDF.index)] = [userID, 'Highlights', cntHighlights, highlightDuration//10]
userInteractionSummaryDF.loc[len(userInteractionSummaryDF.index)] = [userID, 'Documents Opened', cntDocumentsOpened, readDuration//10]
userInteractionSummaryDF.loc[len(userInteractionSummaryDF.index)] = [userID, 'Documents Dragged', cntDocumentsDragged, draggingDuration//10]
userInteractionSummaryDF

userInteractionSummaryDF.to_excel(r'/content/drive/My Drive/Colab Notebooks/Proj/d3u8ILogSummary.xlsx')